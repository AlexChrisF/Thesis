@misc{GitHut,
	title = {{GitHut - Programming Languages and GitHub}},
	url = {http://githut.info/},
	note = {Last accesed on 2018-05-15},
}


@book { GOLL,
	author={{Goll, Joachim}},
	title={{}Architektur- und Entwurfsmuster der Softwaretechnik}},
	publisher={Springer Vieweg},
	year={2013},
	language={Deutsch}
}


@misc{ Flux,
	title = {{Flux Software Architecture}},
	author = {Facebook Inc.},
	year={2013},
	url ={https://facebook.github.io/flux/docs/overview.html},
	note = {Last accesed on 2018-05-15},	
}

@misc{ NPM,
	title = {{Downloaded NPM Packages}},
	url ={http://www.npmtrends.com/angular-vs-react-vs-vue-vs-@angular/core},
	note = {Last accesed on 2018-05-15},
}

@misc{ React,
	title = {{Official React Tutorial}},
	url = {https://reactjs.org/tutorial/tutorial.html},
	note = {Last accesed on 2018-05-15},
}


@mis{ Sigmoid,
	title = {{Activation functions}},
	url =  {https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6},
	note = {Last accesed on 2018-05-15},
}

@article{Ratner2017,
	abstract = {Data augmentation is a ubiquitous technique for increasing the size of labeled training sets by leveraging task-specific data transformations that preserve class labels. While it is often easy for domain experts to specify individual transformations, constructing and tuning the more sophisticated compositions typically needed to achieve state-of-the-art results is a time-consuming manual task in practice. We propose a method for automating this process by learning a generative sequence model over user-specified transformation functions using a generative adversarial approach. Our method can make use of arbitrary, non-deterministic transformation functions, is robust to misspecified user input, and is trained on unlabeled data. The learned transformation model can then be used to perform data augmentation for any end discriminative model. In our experiments, we show the efficacy of our approach on both image and text datasets, achieving improvements of 4.0 accuracy points on CIFAR-10, 1.4 F1 points on the ACE relation extraction task, and 3.4 accuracy points when using domain-specific transformation operations on a medical imaging dataset as compared to standard heuristic augmentation approaches.},
	archivePrefix = {arXiv},
	arxivId = {1709.01643},
	author = {Ratner, Alexander J. and Ehrenberg, Henry R. and Hussain, Zeshan and Dunnmon, Jared and R{\'{e}}, Christopher},
	eprint = {1709.01643},
	month = {sep},
	title = {{Learning to Compose Domain-Specific Transformations for Data Augmentation}},
	url = {http://arxiv.org/abs/1709.01643},
	year = {2017}
}


@MastersThesis{Dao,
	author     =     {David Dao},
	title     =     {{Image-based chemical-genetic profiling using Deep Neural Networks}},
	school     =     {TECHNISCHE Universität München},
	year     =     {2016},
}



@article{Scheeder2018,
	abstract = {The increase in imaging throughput, new analytical frameworks and high-performance computational resources open new avenues for data-rich phenotypic profiling of small molecules in drug discovery. Image-based profiling assays assessing single-cell phenotypes have been used to explore mechanisms of action, target efficacy and toxicity of small molecules. Technological advances to generate large data sets together with new machine learning approaches for the analysis of high-dimensional profiling data create opportunities to improve many steps in drug discovery. In this review, we will discuss how recent studies applied machine learning approaches in functional profiling workflows with a focus on chemical genetics. While their utility in image-based screening and profiling is predictably evident, examples of novel insights beyond the status quo based on the applications of machine learning approaches are just beginning to emerge. To enable discoveries, future studies also need to develop methodologies that lower the entry barriers to high-throughput profiling experiments by streamlining image-based profiling assays and providing applications for advanced learning technologies such as easy to deploy deep neural networks.},
	author = {Scheeder, Christian and Heigwer, Florian and Boutros, Michael},
	doi = {10.1016/j.coisb.2018.05.004},
	issn = {24523100},
	journal = {Current Opinion in Systems Biology},
	month = {may},
	title = {{Machine learning and image-based profiling in drug discovery}},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S2452310018300027},
	year = {2018}
}



@article{Pau,
	author = {Pau, Gregoire},
	journal = {Image Processing},
		year = {2018},
	title = {{High-throughput image analysis with EBImage EBImage}}
}



@Article{Jones2008,
	author="Jones, Thouis R.
	and Kang, In Han
	and Wheeler, Douglas B.
	and Lindquist, Robert A.
	and Papallo, Adam
	and Sabatini, David M.
	and Golland, Polina
	and Carpenter, Anne E.",
	title="CellProfiler Analyst: data exploration and analysis software for complex image-based screens",
	journal="BMC Bioinformatics",
	year="2008",
	month="Nov",
	day="15",
	volume="9",
	number="1",
	pages="482",
	abstract="Image-based screens can produce hundreds of measured features for each of hundreds of millions of individual cells in a single experiment.",
	issn="1471-2105",
	doi="10.1186/1471-2105-9-482",
	url="https://doi.org/10.1186/1471-2105-9-482"
}




@article{Jones,
	author = {Jones, Thouis R and Carpenter, Anne E and Lamprecht, Michael R and Moffat, Jason and Silver, Serena J and Grenier, Jennifer K and Castoreno, Adam B and Eggert, Ulrike S and Root, David E and Golland, Polina and Sabatini, David M and Scolnick, Edward M},
	file = {::},
	title = {{Scoring diverse cellular morphologies in image-based screens with iterative feedback and machine learning}},
	url = {http://www.pnas.org/content/pnas/106/6/1826.full.pdf}
}



@Article{CellProfiler,
	author="Jones, Thouis R.
	and Kang, In Han
	and Wheeler, Douglas B.
	and Lindquist, Robert A.
	and Papallo, Adam
	and Sabatini, David M.
	and Golland, Polina
	and Carpenter, Anne E.",
	title="CellProfiler Analyst: data exploration and analysis software for complex image-based screens",
	journal="BMC Bioinformatics",
	year="2008",
	month="Nov",
	day="15",
	volume="9",
	number="1",
	pages="482",
	abstract="Image-based screens can produce hundreds of measured features for each of hundreds of millions of individual cells in a single experiment.",
	issn="1471-2105",
	doi="10.1186/1471-2105-9-482",
	url="https://doi.org/10.1186/1471-2105-9-482"
}



@book {Martin2012Agilesoftware,
	author = {Martin, Robert C.},
	title = {Agile software development: principles, patterns, and practices},
	series = {Alan Apt series},
	address = {Upper Sadle River, NJ},
	publisher = {Pearson Prentice Hall},
	year = {2012},
	pages = {XXII, 529  Seiten},
	edition = {Internat. Ed.},
	ISBN = {978-0-13-276058-4},
	ISBN = {0-13-276058-4},
	language = {Englisch},
	keywords = {Agile Softwareentwicklung},
	note = {ES-Flandernstraße},
}





@misc{ HistoryJS1,
	title = {{A brief history of JavaScript ? Ben Aston ? Medium}},
	url = {https://medium.com/@benastontweet/lesson-1a-the-history-of-javascript-8c1ce3bffb17},

	note = {Last accesed on 2018-05-15},
}

@misc{ HistoryJS2,
	title = {{JavaScript is the Future of Enterprise Application Development}},
	url = {https://www.logicroom.co/javascript-is-the-future-of-application-development/},
	note = {Last accesed on 2018-05-15},
}

@misc{ HistoryJS3,
	title = {{Wie unterscheidet sich JavaScript von Java?}},
	url = {https://www.java.com/de/download/faq/java{\_}javascript.xml},
	note = {Last accesed on 2018-05-15},
}


@misc{ HistoryJS3,
	author = {Gartner. M},
	title = {{Marktanteile der Betriebssysteme am Endkundenabsatz von Smartphones weltweit von 2009 bis 2017.}},
	url = {https://de.statista.com/statistik/daten/studie/12885/umfrage/marktanteil-bei-smartphones-nach-betriebssystem-weltweit-seit-2009/l},
	note = {Last accesed on 2018-05-15},
}





